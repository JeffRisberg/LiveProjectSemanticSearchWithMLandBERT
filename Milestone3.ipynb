{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index cretaed in Milestone 2\n",
    "index = faiss.read_index('data/pandemics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    }
   ],
   "source": [
    "# Load a transformers model\n",
    "embedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "# Load a question answering pipeline from Hugging Face Transformers\n",
    "nlp = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.json', 'r') as file:\n",
    "    documents = json.load(file)\n",
    "corpus = [d['text'] for d in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search the documents and retrieve the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the search function from Milestone 2\n",
    "# to add question-answering functionality\n",
    "def find_answer(query: str, documents, k=5):\n",
    "    encoded_query = embedder.encode([query])\n",
    "    top_k = index.search(encoded_query, k)\n",
    "    # Use the transformers question-answering pipeline to find answer in text. This is done for the top_k documents\n",
    "    # that were found to be matching from FAISS index\n",
    "    answers = [nlp(context=documents[_id], question=query) \n",
    "          for _id \n",
    "          in top_k[1][0]]\n",
    "    return sorted(answers, key = lambda x: x[\"score\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:708: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/site-packages/transformers/pipelines/question_answering.py:298: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'epidemics and disasters',\n",
      "  'end': 457,\n",
      "  'score': 0.7145211100578308,\n",
      "  'start': 434},\n",
      " {'answer': 'more than 1.1 million',\n",
      "  'end': 487,\n",
      "  'score': 0.044743359088897705,\n",
      "  'start': 466}]\n"
     ]
    }
   ],
   "source": [
    "# Checking for the query string which was used in Milestone1 and Milestone2 for comparison\n",
    "pprint(find_answer(\"spanish flu casualties\", corpus, k=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top search results:\n",
      "{'score': 0.5752660632133484, 'start': 1211, 'end': 1256, 'answer': 'improved sanitation and access to clean water'}\n",
      "{'score': 0.41623830795288086, 'start': 1322, 'end': 1383, 'answer': 'by giving both the mother and child antiretroviral medication'}\n",
      "{'score': 0.2783833146095276, 'start': 111, 'end': 163, 'answer': 'measures to reduce causes of new infectious diseases'}\n",
      "{'score': 0.15053525567054749, 'start': 900, 'end': 946, 'answer': 'Tracking viral load is used to monitor therapy'}\n",
      "{'score': 0.11565103381872177, 'start': 218, 'end': 244, 'answer': 'administration of vaccines'}\n"
     ]
    }
   ],
   "source": [
    "# Trying a query from the questions.json file\n",
    "query = \"How to prevent the spread of viral infections?\"\n",
    "results = find_answer(query, corpus)\n",
    "\n",
    "print('Top search results:')\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
